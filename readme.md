# LLMRasp Prototype â€” Interface de Voz com LLM via Ollama

Este Ã© um protÃ³tipo desenvolvido como parte do Trabalho de ConclusÃ£o de Curso em CiÃªncia da ComputaÃ§Ã£o, com o objetivo de permitir interaÃ§Ãµes por voz com modelos de linguagem (LLMs), executando localmente com foco em uso offline em ambientes de infraestrutura limitada (como escolas em Ã¡reas remotas), utilizando um **Raspberry Pi**.

---

## ðŸ“¦ Requisitos

- [Python](https://www.python.org/) 3.11.9 (gerenciado com [pyenv](https://github.com/pyenv/pyenv))
- [Poetry](https://python-poetry.org/)
- [Ollama](https://ollama.com/) instalado e rodando localmente
- Linux (desenvolvido e testado em ambiente Debian-based)

---

## ðŸš€ ConfiguraÃ§Ã£o do Ambiente

### 1. Instale e selecione a versÃ£o correta do Python com `pyenv`:

```bash
pyenv install 3.11.9
pyenv local 3.11.9
```

# 2. DependÃªncias, Ollama + Poetry
```bash
sudo apt update
sudo apt install libportaudio2 portaudio19-dev libportaudiocpp0 ffmpeg
curl -sSf https://ollama.com/install.sh | sh
poetry env use 3.11.9
poetry install
```

# 3. Execute os dois serviÃ§os
source .venv/bin/activate
sudo env "PATH=$PATH" poetry run python main.py 
poetry run uvicorn ollama_handler:app --reload

# 4. Testa API Handler Individualmente (ajustar PORT)
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Fale quanto Ã© 5+5",
    "pre-prompt": "Be clear, serious, and answer fast: ",
    "model": "qwen3:4b"
  }'

## 4.1 Liberar MemÃ³ria do Modelo (ajustar PORT ollama)
curl http://localhost:11434/api/generate \
  -d '{
    "model": "gemma3:1b",
    "keep_alive": 0
  }'

# Autor
Ulian Gabriel Alff Ramires - 2025
ugaramires@inf.ufpel.edu.br